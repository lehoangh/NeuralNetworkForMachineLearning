{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of content\n",
    "1. [Learning to predict the next word](#intro)  \n",
    "1.1. [A relational learning task](#rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to predict the next word\n",
    "<a id=\"intro\"></a>\n",
    "* Aim: Using backpropagation algorithm to learn the feature representation of the meaning of the word.\n",
    "* Example: simple one, but slow that shows idea about how can take some relational information, then use backpropagation algorithm to turn relational information into feature vectors that capture the meanings of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A relational learning task\n",
    "<a id=\"rel\"></a>\n",
    "- A simple example is a diagram shows a simple family tree (a simple example of relational information).\n",
    "- Task: use backpropagation neural network to understand the information in this family tree.\n",
    "- The first diagram ($\\color{black}{top}$) is English family tree, and the second diagram ($\\color{red}{bottom}$) is Italian family tree.\n",
    "![family tree](images/family_tree.png?raw=true)\n",
    "- The information of these family trees can be expressed as a set of propositions (naming the relationships in family trees and using those relationships to write down a set of triples)\n",
    "- The relational learning task is defined the task of learning the information in those family trees, can be viewed as figuring out the **regularities** in a **large set of triples** that express the information in those trees\n",
    " - The obvious way to express the regularities is **symbolic rules**\n",
    "   - Ex: $(x\\ has-mother\\ y)\\ \\&\\ (y\\ has-husband\\ z)\\rightarrow(x\\ has-father\\ z)$\n",
    " - Can search the such rules, but this would involve a search through quite a large space, a combinationally large space of discrete possibilities. (Finding the symbolic rules involves a difficult search through a very large discrete space of possibilities)\n",
    "- Another way is to use a neural network that searches through a continuous space of real-valued weights to try and capture the information.\n",
    "- The way that a neural net capturing the information (The structure of the neural net) = can predict the third terminal triple from the first two terms\n",
    "![neural net structure](images/neural_net_structure.png?raw=True)\n",
    "**Explanation**: At the bottom, putting in a person and a relationship, and the information is going to flow **forwards** through this neural network. What we're going to try to get out of this neural network after it's learned is the person who's related to the first person by that relationship.  \n",
    "* _Step 1_: What we do is we encode the information in a neural way:  \n",
    "    - There're $24$ possible people $\\rightarrow$ the block at the bottom (local encoding of person $1$) has $24$ neurons, and exactly one of those will be turned **on** for each training case.  \n",
    "    - Similarly, there're $12$ relationships, and exactly one of the relationship units will be turned **on**.\n",
    "Question for encoding the person:\n",
    "![question 1 p1](images/question_1.png?raw=True)\n",
    "![question 1 p2](images/question_2.png?raw=True)\n",
    "* _Step 2_: Then, for a relationship that has a **unique** answer, we would like one of the $24$ people at the top (one of the $24$ output people to turn **on** to represent the answer.  \n",
    "(By using a representation in which exactly **one** of the neurons is **on** $\\rightarrow$ don't accidentally give the network any similarities between people. All pairs of people are equally dissimilar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
